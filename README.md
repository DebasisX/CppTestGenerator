# C++ Test Generator with Ollama and MistralÂ 7B

[![Build Status](https://img.shields.io/badge/build-passing-brightgreen)]() [![Coverage](https://img.shields.io/badge/coverage-100%25-blue)]() [![License](https://img.shields.io/badge/license-MIT-blue.svg)]()

Automate unit test generation for C++ code using local LLMs (Ollama with MistralÂ 7B). Generate tests, handle build errors, refine code, and calculate coverageâ€”all offline.

---

## ğŸ“ Table of Contents

- [ğŸš€ Project Structure](#-project-structure)  
- [âš™ï¸ Setup Instructions](#ï¸-setup-instructions)  
- [ğŸ› ï¸ Usage](#ï¸-usage)  
- [ğŸ”„ Workflow Process](#-workflow-process)  
  - [Test Generation](#test-generation)  
  - [Build & Refinement](#build--refinement)  
  - [Coverage Calculation](#coverage-calculation)  
- [âš™ï¸ Customization](#-customization)  
- [ğŸ Troubleshooting](#-troubleshooting)  
- [âœ¨ Key Features](#-key-features)  
- [ğŸš§ Next Steps](#-next-steps)  
- [ğŸ“œ License](#-license)  

---

## ğŸš€ Project Structure

```
C-TestGenerator/
â”œâ”€â”€ src/                   # Source C++ files
â”‚   â”œâ”€â”€ myfile.cpp
â”‚   â””â”€â”€ myfile.h
â”œâ”€â”€ tests/                 # Generated unit tests
â”œâ”€â”€ instructions/          # LLM prompt templates
â”‚   â”œâ”€â”€ generate_tests.yaml
â”‚   â””â”€â”€ fix_tests.yaml
â”œâ”€â”€ scripts/               # Automation scripts
â”‚   â”œâ”€â”€ generate_tests.py
â”‚   â””â”€â”€ run_tests.sh
â””â”€â”€ README.md              # This file
```

---

## âš™ï¸ Setup Instructions

1. **Install Dependencies**  
   ```bash
   sudo apt update
   sudo apt install -y g++ libgtest-dev cmake lcov
   ```
2. **Build Google Test**  
   ```bash
   sudo bash -c 'cd /usr/src/googletest && cmake . && make && cp lib/*.a /usr/lib'
   ```
3. **Install Ollama**  
   ```bash
   curl -fsSL https://ollama.com/install.sh | sh
   ollama pull mistral
   ```
4. **Start Ollama Server**  
   ```bash
   ollama serve
   ```

---

## ğŸ› ï¸ Usage

- **Generate Tests:**  
  ```bash
  python3 scripts/generate_tests.py
  ```
- **Run Tests & View Coverage:**  
  ```bash
  bash scripts/run_tests.sh
  ```
- **View Results:**  
  - Generated tests: `tests/`  
  - Coverage report: `coverage.txt`  

---

## ğŸ”„ Workflow Process

### Test Generation

1. Reads C++ files from `src/`
2. Sends code to Ollama with instructions from `instructions/generate_tests.yaml`
3. Saves generated tests into `tests/`

### Build & Refinement

1. Attempts to build tests
2. If build fails, sends errors to Ollama for fixes (using `instructions/fix_tests.yaml`)
3. Retry up to 3 refinement attempts

### Coverage Calculation

1. Runs successful tests
2. Generates coverage report via `gcov`/`lcov`
3. Outputs coverage percentage to `coverage.txt`

---

## âš™ï¸ Customization

- **Modify Instructions:**  
  Edit YAML files in `instructions/`:
  - `generate_tests.yaml` â€“ initial test generation rules
  - `fix_tests.yaml` â€“ error correction rules

- **Add Source Files:**  
  Place new `.cpp` files in `src/`

- **Change LLM Model:**  
  Edit the `MODEL` variable in `scripts/generate_tests.py` (e.g., `"mistral"`, `"llama2"`, `"codellama"`)

---

## ğŸ Troubleshooting

- **Ollama Errors:**  
  - Ensure `ollama serve` is running  
  - Verify model is downloaded: `ollama list`  

- **Build Failures:**  
  - Check Google Test installation  
  - Verify header paths in `run_tests.sh`  

- **Permission Issues:**  
  - Prefix commands with `sudo` as needed  

---

## âœ¨ Key Features

- **Local LLM Processing:** Offline test generation with Ollama + MistralÂ 7B  
- **Automated Refinement:** Self-corrects via build error feedback  
- **Coverage Integration:** Standard GNU coverage tools (`gcov`, `lcov`)  
- **Easy Customization:** Modify behavior via YAML prompts  

---

## ğŸš§ Next Steps

1. Support multi-file C++ projects  
2. Add CI/CD integration  
3. Experiment with other LLM models  
4. Enhance test coverage metrics and reporting  

THANKS
------
Debasis Sikdar